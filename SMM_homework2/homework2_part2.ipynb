{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"text-align: center;\"><img src=\"classificationDigit.png\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "file_path = 'classificationDigit.png'\n",
    "html_code = f'<div style=\"text-align: center;\"><img src=\"{file_path}\"></div>'\n",
    "HTML(html_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"text-align: center;\"><img src=\"classificationDigit2.png\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "file_path = 'classificationDigit2.png'\n",
    "html_code = f'<div style=\"text-align: center;\"><img src=\"{file_path}\"></div>'\n",
    "HTML(html_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"text-align: center;\"><img src=\"Digitexe.png\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "file_path = 'Digitexe.png'\n",
    "html_code = f'<div style=\"text-align: center;\"><img src=\"{file_path}\"></div>'\n",
    "HTML(html_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 319)\n",
      "(256, 252)\n",
      "(256, 202)\n",
      "(256, 131)\n",
      "(256, 122)\n",
      "(256, 88)\n",
      "(256, 151)\n",
      "(256, 166)\n",
      "(256, 144)\n",
      "(256, 132)\n",
      "[[0.     0.     0.     ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]\n",
      " ...\n",
      " [0.     0.1645 0.     ... 0.     0.     0.    ]\n",
      " [0.     0.086  0.     ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]]\n",
      "[[6 5 4 ... 7 9 8]]\n",
      "X dimensions: (256, 1707)\n",
      "I dimensions: (1, 1707)\n"
     ]
    }
   ],
   "source": [
    "dataset = scipy.io.loadmat('MNIST.mat')\n",
    "X = dataset['X']\n",
    "I = dataset['I']\n",
    "\n",
    "for i in range(10):\n",
    "    print(X[:,I[0] == i].shape)\n",
    "\n",
    "print(X)\n",
    "print(I)\n",
    "\n",
    "print('X dimensions:', X.shape)\n",
    "print('I dimensions:', I.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Visualize a bunch of datapoints of X with the function plt.imshow. <br>\n",
    "  -Extract from X those columns that corresponds to digits 3 or 4. Those digits represents the\n",
    "classes C1 and C2 defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    # reshape the column vector in a matrix 16x16\n",
    "    image = X[:,i].reshape(16,16)\n",
    "    plt.imshow(image, cmap='gray')  \n",
    "    plt.title(f'Label: {I[0][i]}', fontsize=10)  \n",
    "    plt.axis('off')  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Extract from X those columns that corresponds to digits 3 or 4. Those digits represents the classes C1 and C2 defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns for digits 3 and 4: 253\n",
      "Dimensions of X after extraction: (256, 253)\n",
      "Dimensions of I after extraction: (1, 253)\n"
     ]
    }
   ],
   "source": [
    "digits_cols = [i for i in range(X.shape[1]) if I[0][i] == 3 or I[0][i] == 4]\n",
    "print(f'Number of columns for digits 3 and 4: {len(digits_cols)}')\n",
    "\n",
    "X = X[:,digits_cols]\n",
    "print(f'Dimensions of X after extraction: {X.shape}')\n",
    "\n",
    "I = I[:,digits_cols]\n",
    "print(f'Dimensions of I after extraction: {I.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the obtained dataset in training and testing. From now on, we will only consider the training\n",
    "set. The test set will be only used at the end of the exercise to test the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (256, 202)\n",
      "I_train shape: (1, 202)\n",
      "X_test shape: (256, 51)\n",
      "I_test shape: (1, 51)\n"
     ]
    }
   ],
   "source": [
    "# I'm going to use a 80% of data in the dataset X for the train and 20% for the test.\n",
    "train_ratio = 0.8\n",
    "\n",
    "train_size = int(train_ratio * X.shape[1])\n",
    "indices = np.random.permutation(X.shape[1])\n",
    "\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "\n",
    "# Creation of train and test sets \n",
    "X_train = X[:, train_indices]\n",
    "I_train = I[:, train_indices]\n",
    "X_test = X[:, test_indices]\n",
    "I_test = I[:, test_indices]\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'I_train shape: {I_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'I_test shape: {I_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Create the matrices X1 and X2 defined above from X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of X1 (digit 3): (256, 105)\n",
      "Dimensions of X2 (digit 4): (256, 97)\n"
     ]
    }
   ],
   "source": [
    "X1 = X_train[:,I_train[0] == 3]\n",
    "X2 = X_train[:,I_train[0] == 4]\n",
    "\n",
    "print(f'Dimensions of X1 (digit 3): {X1.shape}')\n",
    "print(f'Dimensions of X2 (digit 4): {X2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Compute the SVD decomposition of X1 and X2 with np.linalg.svd(matrix, full matrices=False) and denote the U-part of the two decompositions as U1 and U2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of U1: (256, 105)\n",
      "Dimensions of S1: (105,)\n",
      "Dimensions of V1T: (105, 105)\n",
      "Dimensions of U2: (256, 97)\n",
      "Dimensions of S2: (97,)\n",
      "Dimensions of V2T: (97, 97)\n"
     ]
    }
   ],
   "source": [
    "U1, S1, VT1 = np.linalg.svd(X1, full_matrices=False)\n",
    "U2, S2, VT2 = np.linalg.svd(X2, full_matrices=False)\n",
    "\n",
    "print(f'Dimensions of U1: {U1.shape}')\n",
    "print(f'Dimensions of S1: {S1.shape}')\n",
    "print(f'Dimensions of V1T: {VT1.shape}')\n",
    "\n",
    "print(f'Dimensions of U2: {U2.shape}')\n",
    "print(f'Dimensions of S2: {S2.shape}')\n",
    "print(f'Dimensions of V2T: {VT2.shape}')\n",
    "\n",
    "# Important note:\n",
    "# By using full_matrices=False, we store only the first p columns of the matrix U1, which are the vectors of the orthogonal basis for the original matrix X1.\n",
    "# As a result, the shape of U1 is 256x106, not 256x256 as it would be in the full matrix form, 106 are the singular values different from zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implications of SVD on the MNIST Dataset\n",
    "\n",
    "- Subspace of R ^256: The column space of X_1 is a subspace of R^256. Each column of X_1 represents a vector in R^256(since each image is flattened into a 256-element vector), and the column space is formed by all possible linear combinations of these columns.\n",
    "\n",
    "- Dimensionality of Column Space: The dimension of this column space is 106, indicated by the number of linearly independent columns in X_1. This implies that there are 106 independent directions or dimensions in the column space of X_1.\n",
    "\n",
    "- Orthogonal Basis in U1: The matrix U1, obtained from the SVD of X_1, contains the first 106 columns that form an orthogonal basis for this column space. Each column of U1 is a vector in R^256, and together they represent all the necessary directions to construct any vector in the column space of X_1.\n",
    "\n",
    "- Practical Implications: This means that although the original images are vectors in a high-dimensional space R^256, their actual variety and the information they carry can be captured and represented in a lower-dimensional subspace (106 dimensions in this case). This allows us to have an efficient representation and dimensionality reduction of data while preserving most of the relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Take an unknown digit y from the test set, and compute y⊥1 = U1(UT1y) and y⊥2 = U2(UT2y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected index: 35\n",
      "The selected image rappresent a : 3\n",
      "Shape of the orthogonal projection onto space of digit 3 (y_ort_1): (256, 1)\n",
      "Shape of the orthogonal projection onto space of digit 4 (y_ort_2): (256, 1)\n"
     ]
    }
   ],
   "source": [
    "random_idx = random.randint(0,I_test.shape[1] - 1)\n",
    "print(f'Randomly selected index: {random_idx}')\n",
    "\n",
    "y = X_test[:,random_idx:random_idx+1]\n",
    "print(f'The selected image rappresent a : {I_test[0][random_idx]}')\n",
    "\n",
    "\n",
    "y_ort_1 = U1 @ (U1.T @ y)\n",
    "y_ort_2 = U2 @ (U2.T @ y)\n",
    "\n",
    "print(f'Shape of the orthogonal projection onto space of digit 3 (y_ort_1): {y_ort_1.shape}')\n",
    "print(f\"Shape of the orthogonal projection onto space of digit 4 (y_ort_2): {y_ort_2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Compute the distances d1 = ||y − y⊥1||2 and d2 = ||y − y⊥2||2 and classify y to C1 if d1 < d2 and to C2 if d2 < d1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance from y to its projection onto space of digit 3: 1.2985815617333103\n",
      "Distance from y to its projection onto space of digit 4: 3.848340655659126\n",
      "Y is a 3!\n"
     ]
    }
   ],
   "source": [
    "d1 = np.linalg.norm(y-y_ort_1,2)\n",
    "d2 = np.linalg.norm(y-y_ort_2,2)\n",
    "print(f\"Distance from y to its projection onto space of digit 3: {d1}\")\n",
    "print(f\"Distance from y to its projection onto space of digit 4: {d2}\")\n",
    "\n",
    "if d1 < d2:\n",
    "    print(\"Y is a 3!\")\n",
    "else:\n",
    "    print(\"Y is a 4!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the experiment for different values of y in the test set. Compute the misclassification number for this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 51)\n",
      "Number of experiment done: 51\n",
      "Number of misclassifications: 0\n"
     ]
    }
   ],
   "source": [
    "misclassifications = 0\n",
    "print(I_test.shape)\n",
    "\n",
    "for i in range(X_test.shape[1]):\n",
    "    y = X_test[:, i:i+1]\n",
    "    y_ort_1 = U1 @ (U1.T @ y)\n",
    "    y_ort_2 = U2 @ (U2.T @ y)\n",
    "\n",
    "    dist_to_3 = np.linalg.norm(y - y_ort_1,2)\n",
    "    dist_to_4 = np.linalg.norm(y - y_ort_2,2)\n",
    "\n",
    "    if dist_to_3 < dist_to_4:\n",
    "        classified_digit = 3\n",
    "    else:\n",
    "        classified_digit = 4\n",
    "\n",
    "    if classified_digit != I_test[0][i]:\n",
    "        misclassifications += 1\n",
    "\n",
    "\n",
    "print(f\"Number of experiment done: {I_test.shape[1]}\")\n",
    "print(f\"Number of misclassifications: {misclassifications}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Repeat the experiment for different digits other than 3 or 4. There is a relationship between the visual similarity of the digits and the classification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "\n",
    "def filter_dataset(X, I, digit1, digit2):\n",
    "    indices = [i for i in range(I.shape[1]) if I[0][i] == digit1 or I[0][i] == digit2]\n",
    "    return X[:, indices], I[:, indices]\n",
    "\n",
    "def split_dataset(X, I, train_ratio=0.8):\n",
    "    num_train = int(train_ratio * X.shape[1])\n",
    "    indices = np.random.permutation(X.shape[1])\n",
    "    return X[:, indices[:num_train]], I[:, indices[:num_train]], X[:, indices[num_train:]], I[:, indices[num_train:]]\n",
    "\n",
    "def calculate_svd(X_train, I_train, digit_label):\n",
    "    X_digit = X_train[:, I_train[0] == digit_label]\n",
    "    U, S, VT = np.linalg.svd(X_digit, full_matrices=False)\n",
    "    return U\n",
    "\n",
    "def classify_image(y, U1, U2, digit1, digit2):\n",
    "    y_ort_1 = U1 @ (U1.T @ y)\n",
    "    y_ort_2 = U2 @ (U2.T @ y)\n",
    "\n",
    "    dist_to_digit1 = np.linalg.norm(y - y_ort_1)\n",
    "    dist_to_digit2 = np.linalg.norm(y - y_ort_2)\n",
    "\n",
    "    if dist_to_digit1 < dist_to_digit2:\n",
    "        return digit1 \n",
    "    else:\n",
    "        return digit2\n",
    "\n",
    "\n",
    "def calculate_error_rate(X, I, digit1, digit2, train_ratio=0.8):\n",
    "    X_filtered, I_filtered = filter_dataset(X, I, digit1, digit2)\n",
    "    X_train, I_train, X_test, I_test = split_dataset(X_filtered, I_filtered, train_ratio)\n",
    "    \n",
    "    U1 = calculate_svd(X_train,I_train, digit1)\n",
    "    U2 = calculate_svd(X_train,I_train, digit2)\n",
    "\n",
    "    misclassifications = 0\n",
    "    for i in range(X_test.shape[1]):\n",
    "        y = X_test[:, i:i+1]\n",
    "        classified_digit = classify_image(y, U1, U2, digit1, digit2)\n",
    "        if classified_digit != I_test[0][i]:\n",
    "            misclassifications += 1\n",
    "\n",
    "    error_rate = misclassifications / X_test.shape[1]\n",
    "\n",
    "    return misclassifications,error_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassifications for digits 0 and 2: 35\n",
      "Error rate for digits 0 and 2: 33.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "dataset = scipy.io.loadmat('MNIST.mat')\n",
    "X = dataset['X']\n",
    "I = dataset['I']\n",
    "digit1 = int(input(\"Enter the first digit: \"))\n",
    "digit2 = int(input(\"Enter the second digit: \"))\n",
    "result = calculate_error_rate(X, I, digit1, digit2)\n",
    "print(f\"Misclassifications for digits {digit1} and {digit2}: {result[0]}\")\n",
    "print(f\"Error rate for digits {digit1} and {digit2}: {str(result[1] * 100) + ' %'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 pairs with highest misclassifications rates:\n",
      "Couple 0-8 : Error Rate = 35.48 %\n",
      "Couple 0-9 : Error Rate = 35.16 %\n",
      "Couple 0-2 : Error Rate = 33.33 %\n",
      "Couple 0-3 : Error Rate = 33.33 %\n",
      "Couple 0-4 : Error Rate = 28.09 %\n",
      "Couple 0-7 : Error Rate = 27.84 %\n",
      "Couple 0-6 : Error Rate = 26.60 %\n",
      "Couple 1-9 : Error Rate = 25.97 %\n",
      "Couple 0-5 : Error Rate = 24.39 %\n",
      "Couple 2-5 : Error Rate = 20.69 %\n",
      "Couple 1-8 : Error Rate = 11.25 %\n",
      "Couple 5-8 : Error Rate = 10.64 %\n",
      "Couple 1-4 : Error Rate = 9.33 %\n",
      "Couple 3-5 : Error Rate = 9.09 %\n",
      "Couple 1-5 : Error Rate = 8.82 %\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "error_rates = {}\n",
    "for digit1, digit2 in itertools.combinations(range(10), 2): \n",
    "    misclassifications, error_rate = calculate_error_rate(X, I, digit1, digit2)\n",
    "    error_rates[(digit1, digit2)] = error_rate\n",
    "\n",
    "sorted_error_rates = sorted(error_rates.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 15 pairs with highest misclassifications rates:\")\n",
    "for (digit1, digit2), error_rate in sorted_error_rates[:15]:\n",
    "   print(f\"Couple {digit1}-{digit2} : Error Rate = {error_rate * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Greater Variability for \"0\": The larger number of images for the digit \"0\" in the dataset 319 of 1707 may introduce greater variability in terms of writing styles. This increased variability can make it more challenging for the algorithm to capture a consistent and distinctive representation of this digit.\n",
    "\n",
    "- Dataset Imbalance: Overrepresentation of a certain digit in the dataset could impact the learning process and subsequent classification. \n",
    "\n",
    "- Impact on U Matrices: During SVD, a higher number of images might lead to a more complex or varied U matrix for that digit, affecting the algorithm's ability to accurately distinguish that digit from others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"text-align: center;\"><img src=\"Digitexe2.png\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "file_path = 'Digitexe2.png'\n",
    "html_code = f'<div style=\"text-align: center;\"><img src=\"{file_path}\"></div>'\n",
    "HTML(html_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(X, I, digits):\n",
    "    indices = [i for i in range(I.shape[1]) if I[0][i] in digits]\n",
    "    return X[:, indices], I[:, indices]\n",
    "\n",
    "\n",
    "def calculate_svd_multiclass(X_train, I_train, digit_labels):\n",
    "    Us = {}\n",
    "    for digit in digit_labels:\n",
    "        Us[digit] = calculate_svd(X_train, I_train, digit)\n",
    "    return Us\n",
    "\n",
    "\n",
    "def classify_image_multiclass(y, Us, digits):\n",
    "    min_dist = np.Inf\n",
    "    classified_digit = None\n",
    "    for digit in digits:\n",
    "        U = Us[digit]\n",
    "        y_ort = U @ (U.T @ y)\n",
    "        dist = np.linalg.norm(y - y_ort)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            classified_digit = digit\n",
    "    return classified_digit\n",
    "\n",
    "\n",
    "def calculate_error_rate_multiclass(X, I, digits, train_ratio=0.8):\n",
    "    X_filtered, I_filtered = filter_dataset(X, I, digits)\n",
    "    X_train, I_train, X_test, I_test = split_dataset(X_filtered, I_filtered, train_ratio)\n",
    "\n",
    "    Us = calculate_svd_multiclass(X_train, I_train, digits)\n",
    "\n",
    "    misclassifications = 0\n",
    "    for i in range(X_test.shape[1]):\n",
    "        y = X_test[:, i:i+1]\n",
    "        classified_digit = classify_image_multiclass(y, Us, digits)\n",
    "        if classified_digit != I_test[0][i]:\n",
    "            misclassifications += 1\n",
    "\n",
    "    error_rate = misclassifications / X_test.shape[1]\n",
    "\n",
    "    return misclassifications, error_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 triples with highest misclassifications rates:\n",
      "Couple (0, 8, 9) : Error Rate = 57.98 %\n",
      "Couple (0, 7, 8) : Error Rate = 54.76 %\n",
      "Couple (0, 2, 7) : Error Rate = 54.35 %\n",
      "Couple (0, 6, 7) : Error Rate = 50.78 %\n",
      "Couple (0, 4, 9) : Error Rate = 50.43 %\n",
      "Couple (0, 2, 9) : Error Rate = 50.38 %\n",
      "Couple (0, 5, 7) : Error Rate = 49.57 %\n",
      "Couple (0, 2, 8) : Error Rate = 48.12 %\n",
      "Couple (0, 3, 8) : Error Rate = 47.90 %\n",
      "Couple (0, 2, 6) : Error Rate = 47.41 %\n",
      "Couple (0, 6, 8) : Error Rate = 47.15 %\n",
      "Couple (0, 4, 5) : Error Rate = 46.23 %\n",
      "Couple (0, 7, 9) : Error Rate = 45.97 %\n",
      "Couple (0, 4, 7) : Error Rate = 45.90 %\n",
      "Couple (0, 2, 3) : Error Rate = 45.80 %\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "error_rates = {}\n",
    "for digits in itertools.combinations(range(10), 3): \n",
    "    misclassifications, error_rate = calculate_error_rate_multiclass(X, I, digits)\n",
    "    error_rates[digits] = error_rate\n",
    "\n",
    "sorted_error_rates = sorted(error_rates.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 15 triples with highest misclassifications rates:\")\n",
    "for digits,error_rate in sorted_error_rates[:15]:\n",
    "   print(f\"Couple {digits} : Error Rate = {error_rate * 100:.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4485451d304caa8f4c9dd363991b164c5fe2ca05e2672d978ba2d9ef4990cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
