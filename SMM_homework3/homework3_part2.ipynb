{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"text-align: center;\"><img src=\"homework3_part2_images/expl_home3.png\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "file_path = 'homework3_part2_images/expl_home3.png'\n",
    "html_code = f'<div style=\"text-align: center;\"><img src=\"{file_path}\"></div>'\n",
    "HTML(html_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"text-align: center;\"><img src=\"homework3_part2_images/stocastic.png\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "file_path = 'homework3_part2_images/stocastic.png'\n",
    "html_code = f'<div style=\"text-align: center;\"><img src=\"{file_path}\"></div>'\n",
    "HTML(html_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_optimizer(l, grad_l, w0, data, alpha, batch_size, n_epochs):\n",
    "    X, y = data  # Unpack the data\n",
    "    N = X.shape[1]\n",
    "    d = w0.shape[0]\n",
    "    idx = np.arange(0, N)\n",
    "    \n",
    "    # Initialization of output arrays\n",
    "    w_history = []\n",
    "    f_val = np.zeros((n_epochs, ))  # Save loss values at the end of each epoch\n",
    "    grads = []\n",
    "    err = np.zeros((n_epochs, ))  # Save gradient norms at the end of each epoch\n",
    "    \n",
    "    # Initialize weights\n",
    "    w = w0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Shuffle the data at the beginning of each epoch\n",
    "        np.random.shuffle(idx)\n",
    "        X_shuffled = X[:, idx]\n",
    "        y_shuffled = y[:, idx]\n",
    "        \n",
    "        for batch_start in range(0, N, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, N)\n",
    "            X_batch = X_shuffled[:, batch_start:batch_end]\n",
    "            y_batch = y_shuffled[:, batch_start:batch_end]\n",
    "            \n",
    "            # Compute the gradient of the loss\n",
    "            #print(X_batch.shape,y_batch.shape)\n",
    "            gradient = grad_l(w, X_batch, y_batch)\n",
    "            \n",
    "            # Update weights\n",
    "            w = w - alpha * gradient\n",
    "            \n",
    "            # Store weights after each update\n",
    "            w_history.append(w)\n",
    "            \n",
    "        # Compute and save loss and gradient norm after each epoch\n",
    "        f_val[epoch] = l(w, X, y)\n",
    "        gradient_epoch = grad_l(w, X, y)\n",
    "        grads.append(gradient_epoch)\n",
    "        err[epoch] = np.linalg.norm(gradient_epoch, 2)\n",
    "    \n",
    "    return np.array(w_history), f_val, np.array(grads), err\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (images): (256, 1707)\n",
      "Shape of I (labels): (1, 1707)\n"
     ]
    }
   ],
   "source": [
    "dataset = scipy.io.loadmat('MNIST.mat')\n",
    "X = dataset['X']\n",
    "I = dataset['I']\n",
    "print(\"Shape of X (images):\", X.shape)\n",
    "print(\"Shape of I (labels):\", I.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_images = 10\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for i in range(num_images):\n",
    "    image = X[:, i]\n",
    "    image = np.reshape(image, (16, 16))\n",
    "    plt.subplot(2, num_images//2, i + 1) \n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Label: {I[0][i]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 275) (1, 275)\n"
     ]
    }
   ],
   "source": [
    "digit1 = int(input('Enter the first digit to select :'))\n",
    "digit2 = int(input('Enter the second digit to select :'))\n",
    "digits_cols = [i for i in range(X.shape[1]) if I[0][i] == digit1 or I[0][i] == digit2]\n",
    "X = X[:,digits_cols]\n",
    "I = I[:,digits_cols]\n",
    "print(X.shape,I.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_images = 10\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for i in range(num_images):\n",
    "    image = X[:, i]\n",
    "    image = np.reshape(image, (16, 16))\n",
    "    plt.subplot(2, num_images//2, i + 1) \n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Label: {I[0][i]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 220) (1, 220) (257, 55) (1, 55)\n"
     ]
    }
   ],
   "source": [
    "# I'm going to use a 80% of data in the dataset X for the train and 20% for the test.\n",
    "#Adding bias\n",
    "bias_row = np.ones((1, X.shape[1]))  \n",
    "X_bias = np.concatenate([bias_row, X], axis=0)  \n",
    "\n",
    "train_elements = int(X_bias.shape[1] * 0.8)\n",
    "\n",
    "\n",
    "X_train = X_bias[:,:train_elements]\n",
    "Y_train = I[:,:train_elements]\n",
    "\n",
    "X_test = X_bias[:,train_elements:]\n",
    "Y_test = I[:,train_elements:]\n",
    "\n",
    "print(X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))\n",
    "\n",
    "def f(w, X):\n",
    "    return sigmoid(np.dot(w.T, X))\n",
    "\n",
    "\n",
    "def loss_mse(w, X, Y):\n",
    "    N = X.shape[1]\n",
    "    y_pred = f(w, X)\n",
    "    loss = (1 / (2 * N)) * np.sum((y_pred - Y) ** 2)\n",
    "    return loss\n",
    "\n",
    "def grad_loss_mse(w, X, Y):\n",
    "    N = X.shape[1]\n",
    "    y_pred = f(w, X)  \n",
    "\n",
    "    error_term = (y_pred - Y) * y_pred * (1 - y_pred)  \n",
    "    if error_term.shape != (1, N):\n",
    "        error_term = error_term.reshape(1, N)\n",
    "        \n",
    "    gradient = (1 / N) * np.dot(X, error_term.T)  \n",
    "\n",
    "    return gradient\n",
    "\n",
    "def convert_labels_to_binary(Y, digitA, digitB):\n",
    "    Y_binary = np.where(Y == digitA, 0, 1)\n",
    "    return Y_binary\n",
    "\n",
    "# def predict(w, X, threshold=0.5):\n",
    "#     prob = f(w, X)\n",
    "#     predictions = [1 if p >= threshold else 0 for p in prob]\n",
    "#     return predictions\n",
    "\n",
    "def predict(w, X, threshold=0.5):\n",
    "    probas = f(w, X)\n",
    "    predictions = (probas >= threshold)  \n",
    "    return predictions.astype(int) \n",
    "\n",
    "\n",
    "def calculate_accuracy(predictions, Y_binary):\n",
    "    return np.mean(predictions == Y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "w0 = np.zeros((X_train.shape[0], 1))\n",
    "alpha = 0.1\n",
    "batch_size = X_train.shape[1] // 5\n",
    "n_epochs = 1000\n",
    "D = (X_train, Y_train)\n",
    "\n",
    "w_history, f_val, grads, err = sgd_optimizer(loss_mse, grad_loss_mse, w0, D, alpha, batch_size, n_epochs)\n",
    "\n",
    "Y_test_binary = convert_labels_to_binary(Y_test, digit1, digit2)\n",
    "final_w = w_history[-1]\n",
    "\n",
    "predictions = predict(final_w, X_test)\n",
    "accuracy = calculate_accuracy(predictions, Y_test_binary)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (images): (256, 1707)\n",
      "Shape of I (labels): (1, 1707)\n",
      "Filtered Data for digits (0, 1): X_filtered.shape = (257, 571), Y_filtered.shape = (1, 571)\n",
      "Data Split: X_train.shape = (257, 285), Y_train.shape = (1, 285), X_test.shape = (257, 286), Y_test.shape = (1, 286)\n",
      "Binary Labels: [[0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0\n",
      "  1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
      "  1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0\n",
      "  1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
      "  0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1]]\n",
      "Accuracy for digits 0, 1 with batch size 32 and training percentage 0.5: 0.9965034965034965\n",
      "Binary Labels: [[0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0\n",
      "  1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
      "  1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0\n",
      "  1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
      "  0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1]]\n",
      "Accuracy for digits 0, 1 with batch size 32 and training percentage 0.7: 0.9965034965034965\n",
      "Binary Labels: [[0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0\n",
      "  1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
      "  1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0\n",
      "  1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
      "  0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1]]\n",
      "Accuracy for digits 0, 1 with batch size 32 and training percentage 0.9: 0.9965034965034965\n",
      "Binary Labels: [[0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0\n",
      "  1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
      "  1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0\n",
      "  1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
      "  0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1]]\n",
      "Accuracy for digits 0, 1 with batch size 64 and training percentage 0.5: 0.9965034965034965\n",
      "Binary Labels: [[0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0\n",
      "  1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
      "  1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0\n",
      "  1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
      "  0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1]]\n",
      "Accuracy for digits 0, 1 with batch size 64 and training percentage 0.7: 0.9965034965034965\n",
      "Binary Labels: [[0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0\n",
      "  1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
      "  1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0\n",
      "  1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
      "  0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1]]\n",
      "Accuracy for digits 0, 1 with batch size 64 and training percentage 0.9: 0.9965034965034965\n",
      "Binary Labels: [[0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0\n",
      "  1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
      "  1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0\n",
      "  1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
      "  0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1]]\n",
      "Accuracy for digits 0, 1 with batch size 128 and training percentage 0.5: 0.9965034965034965\n",
      "Binary Labels: [[0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0\n",
      "  1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
      "  1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0\n",
      "  1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
      "  0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1]]\n",
      "Accuracy for digits 0, 1 with batch size 128 and training percentage 0.7: 0.9965034965034965\n",
      "Binary Labels: [[0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0\n",
      "  1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
      "  0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n",
      "  1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0\n",
      "  1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
      "  0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1]]\n",
      "Accuracy for digits 0, 1 with batch size 128 and training percentage 0.9: 0.9965034965034965\n",
      "Data Split: X_train.shape = (257, 399), Y_train.shape = (1, 399), X_test.shape = (257, 172), Y_test.shape = (1, 172)\n",
      "Binary Labels: [[1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0\n",
      "  0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
      "  1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0]]\n",
      "Accuracy for digits 0, 1 with batch size 32 and training percentage 0.5: 0.9941860465116279\n",
      "Binary Labels: [[1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0\n",
      "  0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
      "  1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0]]\n",
      "Accuracy for digits 0, 1 with batch size 32 and training percentage 0.7: 0.9941860465116279\n",
      "Binary Labels: [[1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0\n",
      "  0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
      "  1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0]]\n",
      "Accuracy for digits 0, 1 with batch size 32 and training percentage 0.9: 0.9941860465116279\n",
      "Binary Labels: [[1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0\n",
      "  0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
      "  1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0]]\n",
      "Accuracy for digits 0, 1 with batch size 64 and training percentage 0.5: 0.9941860465116279\n",
      "Binary Labels: [[1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0\n",
      "  0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
      "  1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0]]\n",
      "Accuracy for digits 0, 1 with batch size 64 and training percentage 0.7: 0.9941860465116279\n",
      "Binary Labels: [[1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0\n",
      "  0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
      "  1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0]]\n",
      "Accuracy for digits 0, 1 with batch size 64 and training percentage 0.9: 0.9941860465116279\n",
      "Binary Labels: [[1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0\n",
      "  0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
      "  1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0]]\n",
      "Accuracy for digits 0, 1 with batch size 128 and training percentage 0.5: 0.9941860465116279\n",
      "Binary Labels: [[1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0\n",
      "  0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
      "  1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0]]\n",
      "Accuracy for digits 0, 1 with batch size 128 and training percentage 0.7: 0.9941860465116279\n",
      "Binary Labels: [[1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0\n",
      "  0 1 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1\n",
      "  1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0]]\n",
      "Accuracy for digits 0, 1 with batch size 128 and training percentage 0.9: 0.9941860465116279\n",
      "Data Split: X_train.shape = (257, 513), Y_train.shape = (1, 513), X_test.shape = (257, 58), Y_test.shape = (1, 58)\n",
      "Binary Labels: [[0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      "  0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1]]\n",
      "Accuracy for digits 0, 1 with batch size 32 and training percentage 0.5: 1.0\n",
      "Binary Labels: [[0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      "  0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1]]\n",
      "Accuracy for digits 0, 1 with batch size 32 and training percentage 0.7: 1.0\n",
      "Binary Labels: [[0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      "  0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1]]\n",
      "Accuracy for digits 0, 1 with batch size 32 and training percentage 0.9: 1.0\n",
      "Binary Labels: [[0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      "  0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1]]\n",
      "Accuracy for digits 0, 1 with batch size 64 and training percentage 0.5: 1.0\n",
      "Binary Labels: [[0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      "  0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1]]\n",
      "Accuracy for digits 0, 1 with batch size 64 and training percentage 0.7: 1.0\n",
      "Binary Labels: [[0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      "  0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1]]\n",
      "Accuracy for digits 0, 1 with batch size 64 and training percentage 0.9: 1.0\n",
      "Binary Labels: [[0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      "  0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1]]\n",
      "Accuracy for digits 0, 1 with batch size 128 and training percentage 0.5: 1.0\n",
      "Binary Labels: [[0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      "  0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1]]\n",
      "Accuracy for digits 0, 1 with batch size 128 and training percentage 0.7: 1.0\n",
      "Binary Labels: [[0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      "  0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1]]\n",
      "Accuracy for digits 0, 1 with batch size 128 and training percentage 0.9: 1.0\n",
      "Filtered Data for digits (2, 3): X_filtered.shape = (257, 333), Y_filtered.shape = (1, 333)\n",
      "Data Split: X_train.shape = (257, 166), Y_train.shape = (1, 166), X_test.shape = (257, 167), Y_test.shape = (1, 167)\n",
      "Binary Labels: [[1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      "  1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0\n",
      "  0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0]]\n",
      "Accuracy for digits 2, 3 with batch size 32 and training percentage 0.5: 0.39520958083832336\n",
      "Binary Labels: [[1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      "  1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0\n",
      "  0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0]]\n",
      "Accuracy for digits 2, 3 with batch size 32 and training percentage 0.7: 0.39520958083832336\n",
      "Binary Labels: [[1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      "  1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0\n",
      "  0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0]]\n",
      "Accuracy for digits 2, 3 with batch size 32 and training percentage 0.9: 0.39520958083832336\n",
      "Binary Labels: [[1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      "  1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0\n",
      "  0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0]]\n",
      "Accuracy for digits 2, 3 with batch size 64 and training percentage 0.5: 0.39520958083832336\n",
      "Binary Labels: [[1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      "  1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0\n",
      "  0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0]]\n",
      "Accuracy for digits 2, 3 with batch size 64 and training percentage 0.7: 0.39520958083832336\n",
      "Binary Labels: [[1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      "  1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0\n",
      "  0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0]]\n",
      "Accuracy for digits 2, 3 with batch size 64 and training percentage 0.9: 0.39520958083832336\n",
      "Binary Labels: [[1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      "  1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0\n",
      "  0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0]]\n",
      "Accuracy for digits 2, 3 with batch size 128 and training percentage 0.5: 0.39520958083832336\n",
      "Binary Labels: [[1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      "  1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0\n",
      "  0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0]]\n",
      "Accuracy for digits 2, 3 with batch size 128 and training percentage 0.7: 0.39520958083832336\n",
      "Binary Labels: [[1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      "  1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0\n",
      "  0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0]]\n",
      "Accuracy for digits 2, 3 with batch size 128 and training percentage 0.9: 0.39520958083832336\n",
      "Data Split: X_train.shape = (257, 233), Y_train.shape = (1, 233), X_test.shape = (257, 100), Y_test.shape = (1, 100)\n",
      "Binary Labels: [[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      "  0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1]]\n",
      "Accuracy for digits 2, 3 with batch size 32 and training percentage 0.5: 0.46\n",
      "Binary Labels: [[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      "  0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1]]\n",
      "Accuracy for digits 2, 3 with batch size 32 and training percentage 0.7: 0.46\n",
      "Binary Labels: [[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      "  0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1]]\n",
      "Accuracy for digits 2, 3 with batch size 32 and training percentage 0.9: 0.46\n",
      "Binary Labels: [[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      "  0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1]]\n",
      "Accuracy for digits 2, 3 with batch size 64 and training percentage 0.5: 0.46\n",
      "Binary Labels: [[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      "  0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1]]\n",
      "Accuracy for digits 2, 3 with batch size 64 and training percentage 0.7: 0.46\n",
      "Binary Labels: [[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      "  0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1]]\n",
      "Accuracy for digits 2, 3 with batch size 64 and training percentage 0.9: 0.46\n",
      "Binary Labels: [[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      "  0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1]]\n",
      "Accuracy for digits 2, 3 with batch size 128 and training percentage 0.5: 0.46\n",
      "Binary Labels: [[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      "  0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1]]\n",
      "Accuracy for digits 2, 3 with batch size 128 and training percentage 0.7: 0.46\n",
      "Binary Labels: [[0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0\n",
      "  0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      "  0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1]]\n",
      "Accuracy for digits 2, 3 with batch size 128 and training percentage 0.9: 0.46\n",
      "Data Split: X_train.shape = (257, 299), Y_train.shape = (1, 299), X_test.shape = (257, 34), Y_test.shape = (1, 34)\n",
      "Binary Labels: [[0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1]]\n",
      "Accuracy for digits 2, 3 with batch size 32 and training percentage 0.5: 0.4117647058823529\n",
      "Binary Labels: [[0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1]]\n",
      "Accuracy for digits 2, 3 with batch size 32 and training percentage 0.7: 0.4117647058823529\n",
      "Binary Labels: [[0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1]]\n",
      "Accuracy for digits 2, 3 with batch size 32 and training percentage 0.9: 0.4117647058823529\n",
      "Binary Labels: [[0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1]]\n",
      "Accuracy for digits 2, 3 with batch size 64 and training percentage 0.5: 0.4117647058823529\n",
      "Binary Labels: [[0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1]]\n",
      "Accuracy for digits 2, 3 with batch size 64 and training percentage 0.7: 0.4117647058823529\n",
      "Binary Labels: [[0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1]]\n",
      "Accuracy for digits 2, 3 with batch size 64 and training percentage 0.9: 0.4117647058823529\n",
      "Binary Labels: [[0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1]]\n",
      "Accuracy for digits 2, 3 with batch size 128 and training percentage 0.5: 0.4117647058823529\n",
      "Binary Labels: [[0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1]]\n",
      "Accuracy for digits 2, 3 with batch size 128 and training percentage 0.7: 0.4117647058823529\n",
      "Binary Labels: [[0 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1]]\n",
      "Accuracy for digits 2, 3 with batch size 128 and training percentage 0.9: 0.4117647058823529\n",
      "Filtered Data for digits (4, 5): X_filtered.shape = (257, 210), Y_filtered.shape = (1, 210)\n",
      "Data Split: X_train.shape = (257, 105), Y_train.shape = (1, 105), X_test.shape = (257, 105), Y_test.shape = (1, 105)\n",
      "Binary Labels: [[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
      "  0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
      "  1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0]]\n",
      "Accuracy for digits 4, 5 with batch size 32 and training percentage 0.5: 0.3904761904761905\n",
      "Binary Labels: [[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
      "  0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
      "  1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0]]\n",
      "Accuracy for digits 4, 5 with batch size 32 and training percentage 0.7: 0.3904761904761905\n",
      "Binary Labels: [[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
      "  0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
      "  1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0]]\n",
      "Accuracy for digits 4, 5 with batch size 32 and training percentage 0.9: 0.3904761904761905\n",
      "Binary Labels: [[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
      "  0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
      "  1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0]]\n",
      "Accuracy for digits 4, 5 with batch size 64 and training percentage 0.5: 0.3904761904761905\n",
      "Binary Labels: [[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
      "  0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
      "  1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0]]\n",
      "Accuracy for digits 4, 5 with batch size 64 and training percentage 0.7: 0.3904761904761905\n",
      "Binary Labels: [[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
      "  0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
      "  1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0]]\n",
      "Accuracy for digits 4, 5 with batch size 64 and training percentage 0.9: 0.3904761904761905\n",
      "Binary Labels: [[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
      "  0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
      "  1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0]]\n",
      "Accuracy for digits 4, 5 with batch size 128 and training percentage 0.5: 0.3904761904761905\n",
      "Binary Labels: [[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
      "  0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
      "  1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0]]\n",
      "Accuracy for digits 4, 5 with batch size 128 and training percentage 0.7: 0.3904761904761905\n",
      "Binary Labels: [[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
      "  0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1\n",
      "  1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0]]\n",
      "Accuracy for digits 4, 5 with batch size 128 and training percentage 0.9: 0.3904761904761905\n",
      "Data Split: X_train.shape = (257, 147), Y_train.shape = (1, 147), X_test.shape = (257, 63), Y_test.shape = (1, 63)\n",
      "Binary Labels: [[1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1\n",
      "  1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0]]\n",
      "Accuracy for digits 4, 5 with batch size 32 and training percentage 0.5: 0.47619047619047616\n",
      "Binary Labels: [[1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1\n",
      "  1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0]]\n",
      "Accuracy for digits 4, 5 with batch size 32 and training percentage 0.7: 0.47619047619047616\n",
      "Binary Labels: [[1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1\n",
      "  1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0]]\n",
      "Accuracy for digits 4, 5 with batch size 32 and training percentage 0.9: 0.47619047619047616\n",
      "Binary Labels: [[1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1\n",
      "  1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0]]\n",
      "Accuracy for digits 4, 5 with batch size 64 and training percentage 0.5: 0.47619047619047616\n",
      "Binary Labels: [[1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1\n",
      "  1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0]]\n",
      "Accuracy for digits 4, 5 with batch size 64 and training percentage 0.7: 0.47619047619047616\n",
      "Binary Labels: [[1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1\n",
      "  1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0]]\n",
      "Accuracy for digits 4, 5 with batch size 64 and training percentage 0.9: 0.47619047619047616\n",
      "Binary Labels: [[1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1\n",
      "  1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0]]\n",
      "Accuracy for digits 4, 5 with batch size 128 and training percentage 0.5: 0.47619047619047616\n",
      "Binary Labels: [[1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1\n",
      "  1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0]]\n",
      "Accuracy for digits 4, 5 with batch size 128 and training percentage 0.7: 0.47619047619047616\n",
      "Binary Labels: [[1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1\n",
      "  1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0]]\n",
      "Accuracy for digits 4, 5 with batch size 128 and training percentage 0.9: 0.47619047619047616\n",
      "Data Split: X_train.shape = (257, 189), Y_train.shape = (1, 189), X_test.shape = (257, 21), Y_test.shape = (1, 21)\n",
      "Binary Labels: [[1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1]]\n",
      "Accuracy for digits 4, 5 with batch size 32 and training percentage 0.5: 0.38095238095238093\n",
      "Binary Labels: [[1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1]]\n",
      "Accuracy for digits 4, 5 with batch size 32 and training percentage 0.7: 0.38095238095238093\n",
      "Binary Labels: [[1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1]]\n",
      "Accuracy for digits 4, 5 with batch size 32 and training percentage 0.9: 0.38095238095238093\n",
      "Binary Labels: [[1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1]]\n",
      "Accuracy for digits 4, 5 with batch size 64 and training percentage 0.5: 0.38095238095238093\n",
      "Binary Labels: [[1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1]]\n",
      "Accuracy for digits 4, 5 with batch size 64 and training percentage 0.7: 0.38095238095238093\n",
      "Binary Labels: [[1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1]]\n",
      "Accuracy for digits 4, 5 with batch size 64 and training percentage 0.9: 0.38095238095238093\n",
      "Binary Labels: [[1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1]]\n",
      "Accuracy for digits 4, 5 with batch size 128 and training percentage 0.5: 0.38095238095238093\n",
      "Binary Labels: [[1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1]]\n",
      "Accuracy for digits 4, 5 with batch size 128 and training percentage 0.7: 0.38095238095238093\n",
      "Binary Labels: [[1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1]]\n",
      "Accuracy for digits 4, 5 with batch size 128 and training percentage 0.9: 0.38095238095238093\n",
      "{(0, 1): {32: {0.5: 1.0, 0.7: 1.0, 0.9: 1.0}, 64: {0.5: 1.0, 0.7: 1.0, 0.9: 1.0}, 128: {0.5: 1.0, 0.7: 1.0, 0.9: 1.0}}, (2, 3): {32: {0.5: 0.4117647058823529, 0.7: 0.4117647058823529, 0.9: 0.4117647058823529}, 64: {0.5: 0.4117647058823529, 0.7: 0.4117647058823529, 0.9: 0.4117647058823529}, 128: {0.5: 0.4117647058823529, 0.7: 0.4117647058823529, 0.9: 0.4117647058823529}}, (4, 5): {32: {0.5: 0.38095238095238093, 0.7: 0.38095238095238093, 0.9: 0.38095238095238093}, 64: {0.5: 0.38095238095238093, 0.7: 0.38095238095238093, 0.9: 0.38095238095238093}, 128: {0.5: 0.38095238095238093, 0.7: 0.38095238095238093, 0.9: 0.38095238095238093}}}\n"
     ]
    }
   ],
   "source": [
    "def filter_dataset(X, Y, digits):\n",
    "    indices = [i for i in range(Y.shape[1]) if Y[0][i] in digits]\n",
    "    return X[:, indices], Y[:, indices]\n",
    "\n",
    "def train_test_split(X, Y, N_train):\n",
    "\n",
    "    idx = np.arange(0, X.shape[1])\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    train_idx = idx[:N_train]\n",
    "    test_idx = idx[N_train:]\n",
    "    \n",
    "    X_train = X[:, train_idx]\n",
    "    Y_train = Y[:,train_idx]  \n",
    "    X_test = X[:, test_idx]\n",
    "    Y_test = Y[:,test_idx]\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "dataset = scipy.io.loadmat('MNIST.mat')\n",
    "X = dataset['X']\n",
    "I = dataset['I']\n",
    "print(\"Shape of X (images):\", X.shape)\n",
    "print(\"Shape of I (labels):\", I.shape)\n",
    "digits_to_test = [(0, 1), (2, 3), (4, 5)]\n",
    "batch_sizes = [32, 64, 128]\n",
    "training_percentages = [0.5, 0.7, 0.9]\n",
    "results = {}\n",
    "bias_row = np.ones((1, X.shape[1]))  \n",
    "X = np.concatenate([bias_row, X], axis=0) \n",
    "n_epochs = 10\n",
    "alpha = 0.001\n",
    "\n",
    "\n",
    "for digits in digits_to_test:\n",
    "    digitA, digitB = digits\n",
    "    results[digits] = {}\n",
    "    X_copy = X.copy()\n",
    "    I_copy = I.copy()\n",
    "    X_filtered, Y_filtered = filter_dataset(X_copy, I_copy, digits)\n",
    "    print(f\"Filtered Data for digits {digits}: X_filtered.shape = {X_filtered.shape}, Y_filtered.shape = {Y_filtered.shape}\")\n",
    "\n",
    "    for percentage in training_percentages:\n",
    "        N_train = int(percentage * X_filtered.shape[1])\n",
    "        X_train, Y_train, X_test, Y_test = train_test_split(X_filtered, Y_filtered, N_train)\n",
    "        print(f\"Data Split: X_train.shape = {X_train.shape}, Y_train.shape = {Y_train.shape}, X_test.shape = {X_test.shape}, Y_test.shape = {Y_test.shape}\")\n",
    "\n",
    "        for batch_size in batch_sizes:\n",
    "            results[digits][batch_size] = {}\n",
    "            for percentage in training_percentages:\n",
    "                w_history, f_val, grads, err = sgd_optimizer(loss_mse, grad_loss_mse, w0, (X_train, Y_train), alpha, batch_size, n_epochs)\n",
    "                final_w = w_history[-1]\n",
    "                #print(f\"Final Weights for batch_size = {batch_size}, percentage = {percentage}: {final_w}\")\n",
    "\n",
    "                Y_test_binary = convert_labels_to_binary(Y_test, digitA, digitB)\n",
    "                print(f\"Binary Labels: {Y_test_binary[:10]}\")  \n",
    "                predictions = predict(final_w, X_test)\n",
    "                \n",
    "                accuracy = calculate_accuracy(predictions, Y_test_binary)\n",
    "                print(f\"Accuracy for digits {digitA}, {digitB} with batch size {batch_size} and training percentage {percentage}: {accuracy}\")\n",
    "\n",
    "                results[digits][batch_size][percentage] = accuracy\n",
    "\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4485451d304caa8f4c9dd363991b164c5fe2ca05e2672d978ba2d9ef4990cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
